{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **LexisNexis Risk Solutions** <br> *Comparing Two Datasets and Calculating Basic Statistical Differences*\n",
    "\n",
    "*Mentor: Matthew Ludewig (Quality Engineering Lead, LexisNexis Risk Solutions)* <br> *Interns: Sam Bai, Khushi Wadhwa, An Nguyen*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Data analysis is the process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions and supporting decision-making.\n",
    "\n",
    "Data analysis has multiple facets and approaches and encompasses diverse techniques. In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Project at Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> \"This is an analytics based project. We need help creating a python based executable code that can compare 2 datasets with various data types (integer/string) and calculate basic statistical differences between the two. For example, % records different, % records increase, % records decrease, change in cardinality.\n",
    "\n",
    "> The challenge arises when tying to compare changes in string values (list of states for example) Both files would have a column \"Residency State\" and the data within that column is a list (CA,CO,MN) for file A but for file B the list could be (CA,CO,MN,TX). While the value exists in both we would want the change to be represented as an increase for the column since the string is adding one state value.\n",
    "\n",
    "> We will provide 4 to 8 datasets with approximately 50K rows and anywhere from 50-1000 columns to aid in creating the code.\n",
    "> <br> The deliverable should be executable code that can read in 2 datasets of the same structure and output a summarized table of the differences between the 2 files.\n",
    "> <br> We would integrate this code into our team processes for analytical monitoring and research.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Our Team's Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Because our team lives across different time zones in the United States, scheduling proved to be difficult. This was further complicated by every member's own busy personal schedules.\n",
    "\n",
    "As a work around, our team decided to take a more autonomous approach for this project.\n",
    "- Each team member will implement their own Python executable code that will meet the project specifications and requirements.\n",
    "- At any point when implementing our project we feel as though we need a second opinion on our code, we will contact each other and discuss.\n",
    "- For our final meeting, we will present our executable code to the team and explain our solution's approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tools and Technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Python***\n",
    "- Interpreted, high-level, general-purpose programming language\n",
    "- Object-oriented programming language commonly used to streamline large complex data sets\n",
    "- Emphasizes code readability, type fewer lines of code for acomplishing tasks\n",
    "- Hyper flexibility, scalability, well-supported\n",
    "- **Huge libraries collection** *(Pandas, SciPy, StatsModels)*\n",
    "- Open-source language with massive community base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python Libraries and Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### NumPy***\n",
    "https://github.com/numpy/numpy\n",
    "- Fast and versatile n-dimensional arrays\n",
    "- Vectorization, indexing, and broadcasting concepts\n",
    "- Comprehensive mathematical functions and linear algebra routines\n",
    "- Supports wide range of hardware and computing platforms\n",
    "- Well-optimized C code and high level syntax\n",
    "- Open source, responsive and diverse community\n",
    "\n",
    "### Pandas***\n",
    "https://github.com/pandas-dev/pandas\n",
    "- DataFrame: in-memory 2D table object (similar to a spreadsheet)\n",
    "- Easy handling of missing data in floating and non-floating point data\n",
    "- Size mutability - easily insert and delete columns into DataFrame\n",
    "- Automatic and explicit data alignment\n",
    "- Intelligent label-based slicing and subsetting of large data sets\n",
    "- Robust tools for loading from and saving data to .csv and Excel files\n",
    "\n",
    "### SciPy\n",
    "https://github.com/scipy/scipy\n",
    "- Depends on NumPy, built to work with NumPy arrays\n",
    "- Provides user-friendly and efficient numerical routines\n",
    "- Run on all popular operating systems\n",
    "- Easy to use and powerful to manipulate numbers and display results\n",
    "\n",
    "### DataGristle\n",
    "https://github.com/kenfar/DataGristle\n",
    "- Tough and flexible data connectors and analyzers\n",
    "- Interactive mix between ETL and data analysis optimzed for rapid analysis and manipulation\n",
    "- Easily-adopted tool for technical analysts\n",
    "- Strong support for ability to create data dictionaries and change detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Integrated Development Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Jupyter\n",
    "- Free, open-source, interactive web tool known as a computational notebook\n",
    "- Combine software code, computational output, explanatory text and multimedia resources in a single document\n",
    "- Enthusiastic community of users\n",
    "- Laboratory notebooks for scientific computing and data exploration\n",
    "- Requires discipline when it comes to executing code\n",
    "\n",
    "### Spyder\n",
    "- Open-source cross-platform IDE written completely in Python\n",
    "- Designed by scientists and exclusively for scientists, data analysts, and engineers\n",
    "- Availability of breakpoints (debugging and conditional breakpoints)\n",
    "- Provides real-time code introspection\n",
    "- Interactive execution\n",
    "\n",
    "### PyCharm\n",
    "- Intelligent code editor, easy to analyze code and identify errors\n",
    "- Smart code navigation to edit and improve code\n",
    "- Locate items in source code, code snippet, UI element, or user action immediately\n",
    "- Supports widely used web technologies like HTML/CSS, Javascript, etc.\n",
    "- Supports widely used scientific libraries for Python in big data and data science projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:12:21.253854\n",
      "TIME: 741.2548518180847\n"
     ]
    }
   ],
   "source": [
    "# File dimensions: 25000 rows Ã— 398 columns\n",
    "\n",
    "# pandas offers great tools for analyzing data sets, provides in-memory 2d table object called Dataframe\n",
    "# plenty of documentation for the package can be found online, seems to be a great community behind its usage\n",
    "import pandas as pd\n",
    "\n",
    "# numpy package mostly used for determining data types of data values\n",
    "import numpy as np\n",
    "\n",
    "# time and datetime packages used for determining the runtime of code\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# begin timing code\n",
    "start = time.time()\n",
    "begin_time = datetime.datetime.now()\n",
    "\n",
    "# Reading in the two csv files that the script will apply the comparison on\n",
    "base = pd.read_csv(\"s.csv\")\n",
    "test = pd.read_csv(\"LI Test full.csv\")\n",
    "\n",
    "# cols represents the names of the attributes in the file\n",
    "cols = base.columns\n",
    "# index_ used to parse columns for testing purposes\n",
    "index_ = cols.tolist()\n",
    "\n",
    "# reinitialize cols to updated data input size (testing purposes)\n",
    "cols = base.columns\n",
    "# cols_dtypes used to determine the type of data that each attribute represents\n",
    "cols_dtypes = base.dtypes\n",
    "\n",
    "# num used to parse data input\n",
    "num = 25000\n",
    "base = base.head(num)\n",
    "test = test.head(num)\n",
    "\n",
    "# initialize counts that will be used to determine\n",
    "total_counts = [0] * len(cols)\n",
    "diff_counts = [0] * len(cols)\n",
    "up_counts = [0] * len(cols)\n",
    "down_counts = [0] * len(cols)\n",
    "\n",
    "# iterates through each row of the base and test file\n",
    "for (indexf1, rowf1), (indexf2, rowf2) in zip(base.iterrows(), test.iterrows()):\n",
    "    \n",
    "    # iterates through each attribute of a record\n",
    "    for i in range(0, len(cols)):\n",
    "        \n",
    "        # data is a numerical value\n",
    "        if cols_dtypes[i] == np.int64 or cols_dtypes[i] == np.float64:\n",
    "            \n",
    "            # at least one record has data for this specific attribute\n",
    "            if not(rowf1[i] == -1 and rowf2[i] == -1):\n",
    "                total_counts[i] += 1\n",
    "\n",
    "            # f1 < f2 => increase\n",
    "            if rowf1[i] < rowf2[i]:\n",
    "                up_counts[i] += 1\n",
    "                diff_counts[i] += 1\n",
    "                \n",
    "            # f1 > f2 => decrease\n",
    "            elif rowf1[i] > rowf2[i]:\n",
    "                down_counts[i] += 1\n",
    "                diff_counts[i] += 1\n",
    "        \n",
    "        # data is a string value\n",
    "        else:\n",
    "            \n",
    "            # at least one record has data for this specific attribute\n",
    "            if not(rowf1[i] == '-1' and rowf2[i] == '-1'):\n",
    "                total_counts[i] += 1\n",
    "            \n",
    "            # special check for NaN values (not all NaN values equal each other for some reason?)\n",
    "            if not(pd.isna(rowf1[i]) or pd.isna(rowf2[i])):\n",
    "                if (rowf1[i] != rowf2[i]):\n",
    "                    diff_counts[i] += 1\n",
    "\n",
    "# -1 entries will have adverse effects on numerical statistical measures such as mean and standard deviation;\n",
    "# replacing all -1's with NaN bypasses these unintended effects for a more accurate description of the data\n",
    "base = base.replace(-1, np.NaN)\n",
    "test = test.replace(-1, np.NaN)\n",
    "\n",
    "# base_t and test_t hold information on mean and std, applied transpose for easy access of these statistical measures\n",
    "base_t = base.describe().transpose()\n",
    "test_t = test.describe().transpose()\n",
    "\n",
    "# columns of output file represent basic statistical measures\n",
    "index = -1\n",
    "data = []\n",
    "df_columns = ['index', 'dtype', 'field', 'total_cnt', 'diff_cnt', 'diff_pct', 'up_cnt', 'up_pct', 'down_cnt', 'down_pct', \n",
    "              'mean_f1', 'mean_f2', 'mean_diff (f2-f1)', 'std_f1', 'std_f2', 'std_diff (f2-f1)', 'min_f1', 'min_f2', \n",
    "              'max_f1', 'max_f2']\n",
    "\n",
    "# option to exclude any attributes that experienced no changes across all records between the two files\n",
    "excludeNoChange = False\n",
    "\n",
    "# iterate through each attribute and its counts\n",
    "for (x0, x1, x2, x3, x4, x5) in zip(cols_dtypes, cols, total_counts, diff_counts, up_counts, down_counts):\n",
    "    index += 1\n",
    "    if excludeNoChange == True:\n",
    "        if x3 == 0:\n",
    "            continue\n",
    "    \n",
    "    # handles special case where there is a count of 0 to avoid division by 0 error\n",
    "    if (x2 == 0):\n",
    "        row = [index, cols_dtypes[index], x1, x2, x3, -1, x4, -1, x5, -1]\n",
    "    else:\n",
    "        row = [index, cols_dtypes[index], x1, x2, x3, x3/x2*100, x4, x4/x2*100, x5, x5/x2*100]\n",
    "\n",
    "    # numerical statistical measures for numerical data values ONLY\n",
    "    if (x0 == np.int64 or x0 == np.float64):\n",
    "        mean_f1 = base_t['mean'][x1]\n",
    "        mean_f2 = test_t['mean'][x1]\n",
    "        row.extend((mean_f1, mean_f2, mean_f2 - mean_f1))\n",
    "        \n",
    "        std_f1 = base_t['std'][x1]\n",
    "        std_f2 = test_t['std'][x1]\n",
    "        row.extend((std_f1, std_f2, std_f2 - std_f1))\n",
    "        \n",
    "        min_f1 = base_t['min'][x1]\n",
    "        min_f2 = test_t['min'][x1]\n",
    "        row.extend((min_f1, min_f2))\n",
    "        \n",
    "        max_f1 = base_t['max'][x1]\n",
    "        max_f2 = test_t['max'][x1]\n",
    "        row.extend((max_f1, max_f2))\n",
    "    \n",
    "    # numerical statistical measures do NOT apply to string data values \n",
    "    else:\n",
    "        row.extend((np.NaN, np.NaN, np.NaN, np.NaN, np.NaN, np.NaN, 'N/A', 'N/A', 'N/A', 'N/A'))\n",
    "    \n",
    "    data.append(row)\n",
    "\n",
    "# end timing code     \n",
    "print(datetime.datetime.now() - begin_time)\n",
    "end = time.time()\n",
    "print(f\"TIME: {end - start}\")\n",
    "\n",
    "# output DataFrame to .csv file\n",
    "df = pd.DataFrame(data, columns=df_columns)\n",
    "title = f'Sam.csv'\n",
    "#df.to_csv(title, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Khushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:09.761908\n",
      "TIME: 9.762905359268188\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jul  9 15:55:35 2020\n",
    "@author: k9wad\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "*can compare -> figure out if the two files are comparable\n",
    "*cleanup -> clean data\n",
    "*total -> return len\n",
    "num diff -> return num differences\n",
    "percent diff -> return percent different\n",
    "num higher -> return num higher values\n",
    "percent higher -> return percent higher values\n",
    "num lower -> return num lower values\n",
    "percent lower -> return percent lower values\n",
    "*first mean -> return mean of first file\n",
    "*second mean -> return mean of second file\n",
    "*diff mean -> return diff in 2 means\n",
    "*first std -> return standard deviation of first file\n",
    "*second std -> return standard deviation of second file\n",
    "*diff std -> return diff in 2 stds\n",
    "optional: min, max, 25%, 50%, 75%\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "\n",
    "# Check if the files can be compared\n",
    "def canCompare(file1, file2):\n",
    "    return file1.columns.equals(file2.columns)\n",
    "\n",
    "# Output the total number of rows, num/percent differences, num/percent higher, num/percent lower\n",
    "def compare(file1, file2):\n",
    "    diff['total'] = len(file1)\n",
    "    dct1 = file1.to_dict('list')\n",
    "    dct2 = file2.to_dict('list')\n",
    "    \n",
    "    numDiff = np.array([])\n",
    "    numSame = np.array([])\n",
    "    numHigh = np.array([])\n",
    "    numLow = np.array([])\n",
    "    for i in dct1:\n",
    "        higher = 0\n",
    "        lower = 0 \n",
    "        change = 0\n",
    "        same = 0\n",
    "        for (j, k) in it.zip_longest(dct1[i], dct2[i]):\n",
    "            if (k > j):\n",
    "                higher += 1\n",
    "                change += 1\n",
    "            elif (k < j):\n",
    "                lower += 1\n",
    "                change += 1\n",
    "            else:\n",
    "                same += 1\n",
    "        numDiff = np.append(numDiff, change)\n",
    "        numSame = np.append(numSame, same)\n",
    "        numHigh = np.append(numHigh, higher)\n",
    "        numLow = np.append(numLow, lower)\n",
    "        \n",
    "    \n",
    "    diff['num diff'] = numDiff\n",
    "    diff['pct diff'] = (numDiff/len(file1))*100\n",
    "    diff['num same'] = numSame\n",
    "    diff['pct same'] = (numSame/len(file1))*100\n",
    "    diff['num higher'] = numHigh\n",
    "    diff['pct higher'] = (numHigh/len(file1))*100\n",
    "    diff['num lower'] = numLow\n",
    "    diff['pct lower'] = (numLow/len(file1))*100\n",
    "        \n",
    "# Output the mean of each column and the difference in both files\n",
    "def mean(file1, file2):\n",
    "    diff['mean f1'] = np.mean(file1, axis=0)\n",
    "    diff['mean f2'] = np.mean(file2, axis=0)\n",
    "    diff['mean diff'] = np.subtract(np.mean(file1, axis=0), np.mean(file2, axis=0))\n",
    "\n",
    "# Output the standard deviation of each column and the difference in both files\n",
    "def std(file1, file2):\n",
    "    diff['std f1'] = np.std(file1, axis=0)\n",
    "    diff['std f2'] = np.std(file2, axis=0)\n",
    "    diff['std diff'] = np.subtract(np.std(file1, axis=0), np.std(file2, axis=0))\n",
    "\n",
    "# Execute the script in the correct order\n",
    "def start(file1, file2):\n",
    "    if (canCompare(file1, file2)):\n",
    "        compare(file1, file2)\n",
    "        mean(file1, file2)\n",
    "        std(file1, file2)\n",
    "        diff.to_csv('Diff.csv')\n",
    "    else:\n",
    "        print(\"Files are not compatable\")\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "begin_time = datetime.datetime.now()\n",
    "\n",
    "# Import files\n",
    "file1 = pd.read_csv(\"s.csv\")\n",
    "file2 = pd.read_csv(\"LI Test full.csv\")\n",
    "\n",
    "# Cleanup data\n",
    "file1 = file1.select_dtypes(exclude=['object'])\n",
    "file2 = file2.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Setup output\n",
    "diff = pd.DataFrame(data=file1.columns, columns=['attributes'])\n",
    "diff = diff.set_index('attributes')\n",
    "\n",
    "# Execute script\n",
    "start(file1, file2)\n",
    "\n",
    "print(datetime.datetime.now() - begin_time)\n",
    "end = time.time()\n",
    "print(f\"TIME: {end - start_time}\")\n",
    "\n",
    "diff\n",
    "diff.to_csv(f'Khushi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:09:17.916529\n",
      "TIME: 557.9175276756287\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "begin_time = datetime.datetime.now()\n",
    "\n",
    "#get data from csv file\n",
    "fileLIBase_np = np.genfromtxt(\"s.csv\" , usecols=np.arange(0,398), delimiter=\",\", names=True)\n",
    "fileLITest_np = np.genfromtxt(\"LI Test full.csv\", usecols=np.arange(0,398), delimiter=\",\", names=True)\n",
    "\n",
    "sum_diff = 0\n",
    "col_title = []\n",
    "total_cnt_list = []\n",
    "diff_cnt_list = []\n",
    "up_cnt_list = []\n",
    "down_cnt_list = []\n",
    "diff_pct_list = []\n",
    "up_pct_list = []\n",
    "down_pct_list = []\n",
    "matched_list = []\n",
    "mean_Base_list = []\n",
    "mean_Test_list = []\n",
    "standard_dv_list_Base = []\n",
    "standard_dv_list_Test = []\n",
    "change_standard_dv = 0\n",
    "change_standard_dv_list = []\n",
    "character_str_count_list_Base = []\n",
    "character_str_count_list_Test = []\n",
    "blank_list_Base = []\n",
    "blank_list_Test = []\n",
    "\n",
    "#get column title\n",
    "for title in fileLIBase_np.dtype.names:\n",
    "    col_title.append(title)\n",
    "\n",
    "# use for loop through whole columns. len(fileLIBase_np.dtype.names)to get number of columns\n",
    "######################################################################################################################\n",
    "for col in range(len((fileLIBase_np.dtype.names))):\n",
    "    # get all rows for each column.\n",
    "    colBase = fileLIBase_np[fileLIBase_np.dtype.names[col]]\n",
    "    colTest = fileLITest_np[fileLITest_np.dtype.names[col]]\n",
    "    count = 0\n",
    "    diff = 0\n",
    "    up_count = 0\n",
    "    down_count = 0\n",
    "    matched = 0\n",
    "    sum_totalBase = 0.0\n",
    "    sum_totalTest = 0.0\n",
    "    standard_dv_Base = 0\n",
    "    row_BaseValue = []\n",
    "    square_BaseValue = []\n",
    "    item = []\n",
    "    character_str_count_Base = 0\n",
    "    character_str_count_Test = 0\n",
    "    blank_Base = 0\n",
    "    blank_Test = 0\n",
    "\n",
    "    #len(colBase) get number of rows.\n",
    "    # use for loop to get each row.\n",
    "    for row in range(len(colBase)):\n",
    "        if (type(colBase[row]) != str and not math.isnan(colBase[row])):\n",
    "            sum_totalBase += colBase[row]\n",
    "        if (type(colTest[row]) != str and not math.isnan(colTest[row])):\n",
    "            sum_totalTest += colTest[row]\n",
    "\n",
    "        if(type(colBase[row]) != str and math.isnan(colBase[row])):\n",
    "            blank_Base += 1\n",
    "        if (colBase[row] == \"\" and colBase[row] == \"\"):\n",
    "            blank_Base += 1\n",
    "        if (type(colTest[row]) != str and math.isnan(colTest[row])):\n",
    "            blank_Test += 1\n",
    "        if (colTest[row] == \"\" and colTest[row] == \"\"):\n",
    "            blank_Test += 1\n",
    "\n",
    "        if (type(colBase[row]) == str):\n",
    "            get_char_Base = re.split(',|;', colBase[row])\n",
    "            character_str_count_Base += len(get_char_Base)\n",
    "\n",
    "        if (type(colTest[row]) == str):\n",
    "            get_char_Test = re.split(',|;', colTest[row])\n",
    "            character_str_count_Test += len(get_char_Test)\n",
    "\n",
    "        if (colBase[row] == colTest[row]):\n",
    "            matched += 1\n",
    "        elif (colBase[row] != \"\" and colTest[row] == \"\"):\n",
    "             diff += 1\n",
    "        elif (colBase[row] == \"\" and colTest[row] != \"\"):\n",
    "            diff += 1\n",
    "        else:\n",
    "            if (colBase[row] != colTest[row]):\n",
    "                diff += 1\n",
    "\n",
    "            if(type(colBase[row]) == type(colTest[row])):\n",
    "                if (colBase[row] > colTest[row]):\n",
    "                    up_count += 1\n",
    "                elif (colBase[row] < colTest[row]):\n",
    "                    down_count += 1\n",
    "\n",
    "        sum_diff += diff\n",
    "        count += 1\n",
    "\n",
    "        # if (count >= 10):\n",
    "        #     break\n",
    "    # end for (row)\n",
    "    ######################################################################################################################\n",
    "\n",
    "    diff_pct = (100 * diff / count)\n",
    "    up_pct = (100 * up_count / count)\n",
    "    down_pct = (100 * down_count / count)\n",
    "\n",
    "\n",
    "    #check file Base. if type of first row is string, then mean_Base and standard_dv_base is empty.\n",
    "    if (type(colBase[0]) == str):\n",
    "        mean_Base = \"\"\n",
    "        standard_dv_Base = \"\"\n",
    "    # if typpe of colbase is int or float then calculate mean each column.\n",
    "    else:\n",
    "        mean_Base = sum_totalBase/count\n",
    "        sum_dev = 0\n",
    "        for i in range(count):\n",
    "            value = colBase[i]\n",
    "            if(type(value) != str and not math.isnan(value)):\n",
    "                sum_dev += (value - mean_Base) ** 2\n",
    "        standard_dv_Base = math.sqrt(sum_dev / count)\n",
    "\n",
    "    #check file Test.\n",
    "    if (type(colTest[0]) == str):\n",
    "        mean_Test = \"\"\n",
    "        standard_dv_Test = \"\"\n",
    "    else:\n",
    "        mean_Test = sum_totalTest / count\n",
    "        sum_dev = 0\n",
    "        for i in range(count):\n",
    "            value = colTest[i]\n",
    "            if (type(value) != str and not math.isnan(value)):\n",
    "                sum_dev += (value - mean_Base) ** 2\n",
    "        standard_dv_Test = math.sqrt(sum_dev / count)\n",
    "\n",
    "    if (standard_dv_Base == \"\" or standard_dv_Test == \"\"):\n",
    "        change_standard_dv = \"\"\n",
    "    else:\n",
    "        change_standard_dv = standard_dv_Base - standard_dv_Test\n",
    "\n",
    "    total_cnt_list.append(count)\n",
    "    diff_cnt_list.append(diff)\n",
    "    up_cnt_list.append(up_count)\n",
    "    down_cnt_list.append(down_count)\n",
    "    diff_pct_list.append(diff_pct)\n",
    "    up_pct_list.append(up_pct)\n",
    "    down_pct_list.append(down_pct)\n",
    "    matched_list.append(matched)\n",
    "    mean_Base_list.append(mean_Base)\n",
    "    mean_Test_list.append(mean_Test)\n",
    "    standard_dv_list_Base.append(standard_dv_Base)\n",
    "    standard_dv_list_Test.append(standard_dv_Test)\n",
    "    change_standard_dv_list.append(change_standard_dv)\n",
    "    character_str_count_list_Base.append(character_str_count_Base)\n",
    "    character_str_count_list_Test.append(character_str_count_Test)\n",
    "    blank_list_Base.append(blank_Base)\n",
    "    blank_list_Test.append(blank_Test)\n",
    "# end for(col)\n",
    "######################################################################################################################\n",
    "\n",
    "row_title = ['Field','Total_cnt','Diff_cnt','Diff_pct', 'Up_cnt',\n",
    "             'Up_pct','Down_cnt','Down_pct','Matched','Mean_Base',\n",
    "             'Mean_Test','Standard_dev_Base','Standard_dev_Test','Change_standard_dev','Char_str_count_Base',\n",
    "             'Char_str_count_Test',  'Blank_Base', 'Blank_Test']\n",
    "results = [col_title ,total_cnt_list, diff_cnt_list, diff_pct_list,\n",
    "           up_cnt_list, up_pct_list, down_cnt_list, down_pct_list,\n",
    "           matched_list, mean_Base_list, mean_Test_list,\n",
    "           standard_dv_list_Base, standard_dv_list_Test,\n",
    "           change_standard_dv_list,\n",
    "           character_str_count_list_Base,\n",
    "           character_str_count_list_Test,\n",
    "           blank_list_Base,\n",
    "           blank_list_Test]\n",
    "results = np.c_[row_title, results]\n",
    "results = results.transpose()\n",
    "\n",
    "print(datetime.datetime.now() - begin_time)\n",
    "end = time.time()\n",
    "print(f\"TIME: {end - start_time}\")\n",
    "\n",
    "write_np = np.savetxt('An.csv', results, delimiter=',', fmt=\"%s\")\n",
    "# it takes 197 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Autonomy vs Collaboration\n",
    "\n",
    "## Interpretation of Data\n",
    "\n",
    "## No \"One Right Answer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Further Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create a UI to select files to be compared against\n",
    "\n",
    "## Include data visualizations\n",
    "\n",
    "## Better handle non-numerical data\n",
    "\n",
    "## Focus on customizability and applicability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contact Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sam Bai - sbai83100@gmail.com\n",
    "## Khushi Wadhwa - k9wadhwa@gmail.com\n",
    "## An Ngyuen - anguyen.rain@gmail.com"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
